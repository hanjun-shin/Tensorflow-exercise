{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanjun/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# CNN Tensor flow Example\n",
    "# This is code is following 'https://github.com/minsuk-heo/deeplearning/blob/master/src/CNN_Tensorflow.ipynb'\n",
    "import tensorflow as tf\n",
    "# load data from keras\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# the last 10000 dataset set aside for validation \n",
    "x_val = x_train[50000:60000]\n",
    "y_val = y_train[50000:60000]\n",
    "# total 50000 data sets are used for training\n",
    "x_train = x_train[0:50000]\n",
    "y_train = y_train[0:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "import numpy as np\n",
    "\n",
    "x_train = np.reshape(x_train, (50000, 28, 28, 1))\n",
    "x_val = np.reshape(x_val, (10000, 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (10000, 28, 28, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "gray_scale = 255\n",
    "\n",
    "x_train /= gray_scale\n",
    "x_val /= gray_scale\n",
    "x_test /= gray_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial value generating function\n",
    "def weighted_variable(shape) :\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape) :\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filter function\n",
    "def conv2d(x, W) :\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "# Define pooling function\n",
    "def max_pool_2x2(x) :\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define first convolution layer. 5 x 5 x 1 x 16 Input was 5 by 5 and gray scale and apply 16filters \n",
    "W_conv1 = weighted_variable([5,5,1,10])\n",
    "b_conv1 = bias_variable([10])\n",
    "# Define activation function. We use relu function\n",
    "h_conv1 = tf.nn.relu( conv2d(x, W_conv1) + b_conv1)\n",
    "# pooling layer\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define second convolution layer. 5 x 5 x 16 x 32, 32 filters applied\n",
    "W_conv2 = weighted_variable([5, 5, 10, 20])\n",
    "b_conv2 = bias_variable([20])\n",
    "# Define activation function, we use relu function\n",
    "h_conv2 = tf.nn.relu( conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "# pooling layer\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fully connected layer\n",
    "\n",
    "# First hidden layer with 128 nodes \n",
    "W_fc1 = weighted_variable([7*7*20, 128])\n",
    "b_fc1 = bias_variable([128])\n",
    "# Flatting h_pool1\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*20])\n",
    "h_fc1 = tf.nn.relu( tf.matmul( h_pool2_flat, W_fc1) + b_fc1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second hidden layer with 10 nodes\n",
    "W_fc2 = weighted_variable([128, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.nn.relu( tf.matmul(h_fc1, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function : cross-entropy\n",
    "cross_entropy = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y_conv ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer : Adam\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define accuracy and correctness\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: training accuracy: 0.05\n",
      "step 10: training accuracy: 0.514\n",
      "step 20: training accuracy: 0.58\n",
      "step 30: training accuracy: 0.628\n",
      "step 40: training accuracy: 0.608\n",
      "step 50: training accuracy: 0.628\n",
      "step 60: training accuracy: 0.636\n",
      "step 70: training accuracy: 0.632\n",
      "step 80: training accuracy: 0.662\n",
      "step 90: training accuracy: 0.644\n",
      "validation accuracy: 0.6653\n",
      "step 0: training accuracy: 0.632\n",
      "step 10: training accuracy: 0.67\n",
      "step 20: training accuracy: 0.638\n"
     ]
    }
   ],
   "source": [
    "# Train and Test\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "epoch_cnt = 3\n",
    "batch_size = 500\n",
    "iteration = len(x_train) // batch_size\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    tf.set_random_seed(7777)\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(epoch_cnt) :\n",
    "        avg_loss = 0\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        \n",
    "        for i in range(iteration):\n",
    "            if i%10 == 0:\n",
    "                train_accuracy = accuracy.eval(feed_dict={x:x_train[start: end], y_: y_train[start: end]})\n",
    "                print(\"step \"+ str(i) + \": training accuracy: \"+str(train_accuracy))\n",
    "            train_step.run(feed_dict={x:x_train[start: end], y_: y_train[start: end]})\n",
    "            start += batch_size; end += batch_size    \n",
    "        \n",
    "        # Validate model\n",
    "        val_accuracy = accuracy.eval(feed_dict={x:x_val, y_: y_val})\n",
    "        print(\"validation accuracy: \"+str(val_accuracy))\n",
    "        \n",
    "    test_accuracy = accuracy.eval(feed_dict={x:x_test, y_: y_test}) \n",
    "    print(\"test accuracy: \"+str(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
